# ============================================================================
# CORE LLM PROVIDER CONFIGURATION
# ============================================================================

# Primary LLM provider (gemini only for production)
LLM_PROVIDER=gemini

# OpenRouter Configuration - REMOVED for production deployment

# Google Gemini API Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash

# ============================================================================
# ENHANCED INTENT DETECTION CONFIGURATION
# ============================================================================

# Enhanced Intent Detection Toggle
ENABLE_ENHANCED_DETECTION=false
ENABLE_HYBRID_MODE=false
ROLLOUT_PERCENTAGE=0.0

# LLM Configuration for Intent Classification
CLASSIFICATION_MODEL=gemini-2.5-flash
CLASSIFICATION_TEMPERATURE=0.0
CLASSIFICATION_MAX_TOKENS=10
CLASSIFICATION_TIMEOUT_SECONDS=30

# ============================================================================
# SEMANTIC CACHING CONFIGURATION
# ============================================================================

# Cache Backend (memory or redis)
ENABLE_SEMANTIC_CACHE=true
CACHE_BACKEND=memory
CACHE_TTL_SECONDS=3600
MAX_CACHE_SIZE=10000

# Redis Configuration (required if CACHE_BACKEND=redis)
REDIS_URL=redis://localhost:6379/0

# Semantic Similarity Settings
SIMILARITY_THRESHOLD=0.85
EMBEDDING_MODEL=all-MiniLM-L6-v2
ENABLE_EMBEDDING_CACHE=true

# ============================================================================
# PERFORMANCE OPTIMIZATION
# ============================================================================

# Background Processing
ENABLE_BACKGROUND_CACHING=true
CACHE_WARMUP_ON_STARTUP=true
MAX_CONCURRENT_CLASSIFICATIONS=10

# ============================================================================
# MONITORING AND LOGGING
# ============================================================================

# Metrics Collection
ENABLE_DETECTION_METRICS=true
LOG_CLASSIFICATIONS=true
ENABLE_COMPARISON_LOGGING=true

# Alert Thresholds
ACCURACY_ALERT_THRESHOLD=0.85
CACHE_HIT_RATE_ALERT_THRESHOLD=0.40
RESPONSE_TIME_ALERT_THRESHOLD_MS=2000.0

# ============================================================================
# SERVER CONFIGURATION
# ============================================================================

# MCP Server Configuration
MCP_SERVER_URL=http://localhost:8000
MCP_TRANSPORT=http

# FastAPI Server Configuration
FASTAPI_PORT=8001
FASTAPI_HOST=0.0.0.0

# Database Configuration (for MCP server)
DATABASE_PATH=test_data/sample.db
METADATA_PATH=resources/metadata.json

# ============================================================================
# OPENAI COMPATIBILITY SETTINGS
# ============================================================================

# Model Parameters
MAX_TOKENS=2000
TEMPERATURE=0.7

# Retry Configuration
MAX_RETRIES=3
INITIAL_RETRY_DELAY=1.0
MAX_RETRY_DELAY=30.0
RETRY_BACKOFF_FACTOR=2.0

# ============================================================================
# GENERAL CONFIGURATION
# ============================================================================

# Logging Configuration
LOG_LEVEL=INFO

# CORS Configuration
ALLOW_CORS=true

# Optional: Custom site information for OpenRouter
SITE_URL=http://localhost:8001
SITE_NAME=Talk2Tables FastAPI Server

# Ports
export PORT=8000                    # Database MCP server
export PRODUCT_SERVER_PORT=8002     # Product metadata server  